{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate survey results - English Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of entries: 70'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# aggregate all results from English cohorts in a single dataframe\n",
    "#\n",
    "\n",
    "path_results_en = \"../private_data/data/survey_results_en/\"\n",
    "\n",
    "cohorts_en = [\n",
    "    \"2021.09\",\n",
    "    \"2022.01\",\n",
    "    \"2022.03\",\n",
    "    \"2022.06\",\n",
    "    \"2022.09\",\n",
    "    \"2022.11\",\n",
    "    \"2023.02\",\n",
    "    \"2023.05\",\n",
    "    \"2023.07\",\n",
    "    \"2023.10\",\n",
    "    \"2024.01\",\n",
    "    \"2024.04\",\n",
    "    \"2024.07\",\n",
    "    \"2024.09\",\n",
    "    \"2025.01\",\n",
    "]\n",
    "\n",
    "dataframes_en = []\n",
    "\n",
    "for cohort in cohorts_en:\n",
    "    new_df = pd.read_excel(f\"{path_results_en}/results_{cohort}.xlsx\")\n",
    "    dataframes_en.append(new_df)\n",
    "\n",
    "merged_df_en = pd.concat(dataframes_en, ignore_index=True)\n",
    "\n",
    "display(f\"Number of entries: {len(merged_df_en) - 1}\")\n",
    "\n",
    "\n",
    "#\n",
    "# Rename columns\n",
    "#\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../scripts/aggregation/\")))\n",
    "from rename_columns_en import rename_columns_en\n",
    "\n",
    "merged_df_en = rename_columns_en(merged_df_en)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Map names to ct_student_id + remove names + remove comments\n",
    "#\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../private_data/dictionaries_student_data/\")))\n",
    "from dictionary_students_en import dictionary_students_en\n",
    "\n",
    "merged_df_en.insert(2, \"ct_student_id\", None) # add column \"ct_student_id\"\n",
    "for student_name, cohort_id in dictionary_students_en.items():\n",
    "    merged_df_en.loc[merged_df_en['name'].str.strip() == student_name.strip(), \"ct_student_id\"] = cohort_id\n",
    "\n",
    "#\n",
    "# Adding \"cohort_language\" column with \"EN\" value for English cohorts\n",
    "#\n",
    "merged_df_en.insert(4, \"cohort_language\", \"EN\")\n",
    "\n",
    "\n",
    "#\n",
    "# Remove columns that may contain personal data\n",
    "#\n",
    "\n",
    "merged_df_en.drop(\"name\", axis=1, inplace=True)\n",
    "merged_df_en.drop(\"final_comments\", axis=1, inplace=True)\n",
    "merged_df_en.drop(\"Marca temporal\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#\n",
    "# test\n",
    "#\n",
    "# pd.set_option('display.max_rows', None)\n",
    "#display(merged_df_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding \"other\" job hunt blocker to a new column.\n",
    "\n",
    "job_hunt_blockers_list = [\n",
    "  \"I never wanted to find a job as a developer\",\n",
    "  \"I learned that web dev is not for me\",\n",
    "  \"Lack of motivation\",\n",
    "  \"Frustration with the process\",\n",
    "  \"Feeling overwhelmed (too many things to do\",\n",
    "  # the next two relate to the previous entry with a \",\"\n",
    "  \"too many things to learn\",\n",
    "  \"etc)\",\n",
    "\n",
    "  \"Did't see many job offers\",\n",
    "  \"Lack of confidence that I'd find a job\",\n",
    "  \"Procrastination (I want\",\n",
    "  # the next one relate to the previous entry with a \",\"\n",
    "  \"but I keep delaying and postponing)\",\n",
    "\n",
    "  \"Personal life (I'm focusing on other aspects of my personal life)\",\n",
    "  \"Lack of guidance / don't know where to start\",\n",
    "]\n",
    "\n",
    "# Function to find the unknown item\n",
    "def find_unknown(blocker_str, valid_list):\n",
    "    if pd.isna(blocker_str):\n",
    "      return None\n",
    "    items = [item.strip() for item in blocker_str.split(',')]\n",
    "    unknowns = [item for item in items if item not in valid_list]\n",
    "    #todo later, translate other\n",
    "    return unknowns[0] if unknowns else None\n",
    "\n",
    "# Apply the function to each row\n",
    "merged_df_en['other_job_hunt_blocker'] = merged_df_en['job_hunt_blockers'].apply(lambda x: find_unknown(x, job_hunt_blockers_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: removing commas and other characters and simplifying response for simpler EDA later. Repeating those not to be changed so the \"other\" is removed when not found.\n",
    "job_hunt_blockers_dict = {\n",
    "  \"I never wanted to find a job as a developer\": \"I never wanted to find a job as a developer\",\n",
    "  \"I learned that web dev is not for me\": \"I learned that web dev is not for me\",\n",
    "  \"Lack of motivation\": \"Lack of motivation\",\n",
    "  \"Frustration with the process\": \"Frustration with the process\",\n",
    "  \"Feeling overwhelmed (too many things to do\": \"Feeling overwhelmed\",\n",
    "  # the next two relate to the previous entry with a \",\"\n",
    "  \"too many things to learn\": \"\",\n",
    "  \"etc)\": \"\",\n",
    "\n",
    "  \"Did't see many job offers\": \"Did not see many job offers\",\n",
    "  \"Lack of confidence that I'd find a job\": \"Lack of confidence\",\n",
    "  \"Procrastination (I want\": \"Procrastination\",\n",
    "  # the next one relate to the previous entry with a \",\"\n",
    "  \"but I keep delaying and postponing)\": \"\",\n",
    "\n",
    "  \"Personal life (I'm focusing on other aspects of my personal life)\": \"Focusing on Personal life\",\n",
    "  \"Lack of guidance / don't know where to start\": \"Lack of guidance\",\n",
    "}\n",
    "\n",
    "# the lambda will split the substrings and apply the replace for each one\n",
    "def filter_empty(elem):\n",
    "  return elem != \"\"\n",
    "\n",
    "merged_df_en['job_hunt_blockers'] = merged_df_en['job_hunt_blockers'].apply(\n",
    "    lambda string: ', '.join(filter(filter_empty, [job_hunt_blockers_dict.get(substring.strip(), \"Other\") for substring in string.split(',')]))\n",
    "    if pd.notnull(string) else string\n",
    ")\n",
    "# NOTE: adding \"Other\" instead of substring.strip() as a second argument of .get to group other responses. Later can be a different column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding \"other\" job success factor to a new column.\n",
    "\n",
    "job_success_factor_list = [\n",
    "  \"Good communication and soft skills\",\n",
    "  \"Good coding skills\",\n",
    "  \"Strong portfolio or personal projects\",\n",
    "  \"Networking and contacts\",\n",
    "  \"I practiced a lot for technical interviews (e.g. coding challenges)\",\n",
    "  \"I practiced a lot for non-technical interviews (e.g. behavioral questions\",\n",
    "  # the next three relate to the previous entry with a \",\"\n",
    "  \"explaining projects\",\n",
    "  \"etc)\",\n",
    "\n",
    "  \"Discipline and hard work\",\n",
    "  \"Persistance (I got rejected many times but kept applying until I succeeded)\",\n",
    "]\n",
    "\n",
    "# Function to find the unknown item\n",
    "def find_unknown(factor_str, valid_list):\n",
    "    if pd.isna(factor_str):\n",
    "      return None\n",
    "    items = [item.strip() for item in factor_str.split(',')]\n",
    "    unknowns = [item for item in items if item not in valid_list]\n",
    "    #todo later, translate other\n",
    "    return unknowns[0] if unknowns else None\n",
    "\n",
    "# Apply the function to each row\n",
    "merged_df_en['other_job_success_factor'] = merged_df_en['job_success_factors'].apply(lambda x: find_unknown(x, job_success_factor_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: removing commas and other characters and simplifying response for simpler EDA later. Repeating those not to be changed so the \"other\" is removed when not found.\n",
    "job_success_factors_dict = {\n",
    "  \"Good communication and soft skills\": \"Good communication and soft skills\",\n",
    "  \"Good coding skills\": \"Good coding skills\",\n",
    "  \"Strong portfolio or personal projects\": \"Strong portfolio or personal projects\",\n",
    "  \"Networking and contacts\": \"Networking and contacts\",\n",
    "  \"I practiced a lot for technical interviews (e.g. coding challenges)\": \"I practiced a lot for technical interviews\",\n",
    "  \"I practiced a lot for non-technical interviews (e.g. behavioral questions\": \"I practiced a lot for non-technical interviews\",\n",
    "  # the next three relate to the previous entry with a \",\"\n",
    "  \"explaining projects\": \"\",\n",
    "  \"etc)\": \"\",\n",
    "\n",
    "  \"Discipline and hard work\": \"Discipline and hard work\",\n",
    "  \"Persistance (I got rejected many times but kept applying until I succeeded)\": \"Persistance\",\n",
    "}\n",
    "\n",
    "# the lambda will split the substrings and apply the replace for each one\n",
    "\n",
    "def filter_empty(elem):\n",
    "  return elem != \"\"\n",
    "\n",
    "merged_df_en['job_success_factors'] = merged_df_en['job_success_factors'].apply(\n",
    "    lambda string: ', '.join(filter(filter_empty, [job_success_factors_dict.get(substring.strip(), \"Other\") for substring in string.split(',')]))\n",
    "    if pd.notnull(string) else string\n",
    ")\n",
    "\n",
    "# NOTE: adding \"Other\" instead of substring.strip() as a second argument of .get to group other responses. Later can be a different column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join results from English + Spanish cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_data_translated = pd.read_excel(\"../private_data/data/survey_results_es/es_data_translated.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: add cohort language if needed here\n",
    "merged_df_en_es = pd.concat([es_data_translated, merged_df_en])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_en_es.to_excel(\"../private_data/data/survey_results_aggregated/data.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
